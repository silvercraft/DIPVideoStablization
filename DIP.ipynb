{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DIP.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"148NI2zp3jkRyoB5biJz-uVG_PITcjNgG","authorship_tag":"ABX9TyNT2G2BZJG70meiQQXkNU4q"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"EkovL-ATjQdu","executionInfo":{"status":"ok","timestamp":1609599414643,"user_tz":-480,"elapsed":38634,"user":{"displayName":"RNG Silvercraft","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GixYWJwJzPdOQkG39SsvVxUA8iPWxpzup0X_Rfi=s64","userId":"04284112311881935550"}},"outputId":"f9579cb1-9b94-4c5f-ae1c-be450bb19048"},"source":["!pip install -r /requirement.txt"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting astroid==2.4.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/c9/e9c2642dfb169590fb8bdb395f9329da042ee559c2ae7c1e612a3e5f40b4/astroid-2.4.1-py3-none-any.whl (214kB)\n","\u001b[K     |████████████████████████████████| 215kB 5.6MB/s \n","\u001b[?25hRequirement already satisfied: cvxpy==1.0.31 in /usr/local/lib/python3.6/dist-packages (from -r /requirement.txt (line 2)) (1.0.31)\n","Requirement already satisfied: cycler==0.10.0 in /usr/local/lib/python3.6/dist-packages (from -r /requirement.txt (line 3)) (0.10.0)\n","Collecting dill==0.3.1.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c7/11/345f3173809cea7f1a193bfbf02403fff250a3360e0e118a1630985e547d/dill-0.3.1.1.tar.gz (151kB)\n","\u001b[K     |████████████████████████████████| 153kB 5.9MB/s \n","\u001b[?25hRequirement already satisfied: ecos==2.0.7.post1 in /usr/local/lib/python3.6/dist-packages (from -r /requirement.txt (line 5)) (2.0.7.post1)\n","Collecting future==0.18.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n","\u001b[K     |████████████████████████████████| 829kB 7.9MB/s \n","\u001b[?25hCollecting isort==4.3.21\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/b0/c121fd1fa3419ea9bfd55c7f9c4fedfec5143208d8c7ad3ce3db6c623c21/isort-4.3.21-py2.py3-none-any.whl (42kB)\n","\u001b[K     |████████████████████████████████| 51kB 5.9MB/s \n","\u001b[?25hCollecting kiwisolver==1.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/23/147de658aabbf968324551ea22c0c13a00284c4ef49a77002e91f79657b7/kiwisolver-1.2.0-cp36-cp36m-manylinux1_x86_64.whl (88kB)\n","\u001b[K     |████████████████████████████████| 92kB 6.7MB/s \n","\u001b[?25hCollecting lazy-object-proxy==1.4.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0b/dd/b1e3407e9e6913cf178e506cd0dee818e58694d9a5cd1984e3f6a8b9a10f/lazy_object_proxy-1.4.3-cp36-cp36m-manylinux1_x86_64.whl (55kB)\n","\u001b[K     |████████████████████████████████| 61kB 5.6MB/s \n","\u001b[?25hCollecting matplotlib==3.2.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/4b/52da6b1523d5139d04e02d9e26ceda6146b48f2a4e5d2abfdf1c7bac8c40/matplotlib-3.2.1-cp36-cp36m-manylinux1_x86_64.whl (12.4MB)\n","\u001b[K     |████████████████████████████████| 12.4MB 297kB/s \n","\u001b[?25hCollecting mccabe==0.6.1\n","  Downloading https://files.pythonhosted.org/packages/87/89/479dc97e18549e21354893e4ee4ef36db1d237534982482c3681ee6e7b57/mccabe-0.6.1-py2.py3-none-any.whl\n","Collecting multiprocess==0.70.9\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/58/17/5151b6ac2ac9b6276d46c33369ff814b0901872b2a0871771252f02e9192/multiprocess-0.70.9.tar.gz (1.6MB)\n","\u001b[K     |████████████████████████████████| 1.6MB 41.8MB/s \n","\u001b[?25hCollecting nose==1.3.7\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl (154kB)\n","\u001b[K     |████████████████████████████████| 163kB 39.1MB/s \n","\u001b[?25hCollecting numpy==1.18.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/03/27/e35e7c6e6a52fab9fcc64fc2b20c6b516eba930bb02b10ace3b38200d3ab/numpy-1.18.4-cp36-cp36m-manylinux1_x86_64.whl (20.2MB)\n","\u001b[K     |████████████████████████████████| 20.2MB 36.1MB/s \n","\u001b[?25hCollecting opencv-python==4.2.0.34\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/c2/e9cf54ae5b1102020ef895866a67cb2e1aef72f16dd1fde5b5fb1495ad9c/opencv_python-4.2.0.34-cp36-cp36m-manylinux1_x86_64.whl (28.2MB)\n","\u001b[K     |████████████████████████████████| 28.2MB 146kB/s \n","\u001b[?25hRequirement already satisfied: osqp==0.6.1 in /usr/local/lib/python3.6/dist-packages (from -r /requirement.txt (line 16)) (0.6.1)\n","Collecting pylint==2.5.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/6e/36419ec1bd2208e157dff7fc3e565b185394c0dc4901e9e2f983cb1d4b7f/pylint-2.5.2-py3-none-any.whl (324kB)\n","\u001b[K     |████████████████████████████████| 327kB 51.0MB/s \n","\u001b[?25hRequirement already satisfied: pyparsing==2.4.7 in /usr/local/lib/python3.6/dist-packages (from -r /requirement.txt (line 18)) (2.4.7)\n","Requirement already satisfied: python-dateutil==2.8.1 in /usr/local/lib/python3.6/dist-packages (from -r /requirement.txt (line 19)) (2.8.1)\n","Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from -r /requirement.txt (line 20)) (1.4.1)\n","Requirement already satisfied: scs==2.1.2 in /usr/local/lib/python3.6/dist-packages (from -r /requirement.txt (line 21)) (2.1.2)\n","Collecting six==1.14.0\n","  Downloading https://files.pythonhosted.org/packages/65/eb/1f97cb97bfc2390a276969c6fae16075da282f5058082d4cb10c6c5c1dba/six-1.14.0-py2.py3-none-any.whl\n","Collecting toml==0.10.1\n","  Downloading https://files.pythonhosted.org/packages/9f/e1/1b40b80f2e1663a6b9f497123c11d7d988c0919abbf3c3f2688e448c5363/toml-0.10.1-py2.py3-none-any.whl\n","Requirement already satisfied: wrapt==1.12.1 in /usr/local/lib/python3.6/dist-packages (from -r /requirement.txt (line 24)) (1.12.1)\n","Collecting typed-ast<1.5,>=1.4.0; implementation_name == \"cpython\" and python_version < \"3.8\"\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/c1/4cc3c0da2374963f59b2f57ef02e048cdc4f609cbc1184b4146d0812e5b5/typed_ast-1.4.2-cp36-cp36m-manylinux1_x86_64.whl (743kB)\n","\u001b[K     |████████████████████████████████| 747kB 35.3MB/s \n","\u001b[?25hBuilding wheels for collected packages: dill, future, multiprocess\n","  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for dill: filename=dill-0.3.1.1-cp36-none-any.whl size=78533 sha256=a053e6bfd511008e7366b4f03cc9644f277c96c80800cd4a4ea430faac8d2592\n","  Stored in directory: /root/.cache/pip/wheels/59/b1/91/f02e76c732915c4015ab4010f3015469866c1eb9b14058d8e7\n","  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for future: filename=future-0.18.2-cp36-none-any.whl size=491057 sha256=03a4aee39e7aed9dc555df5b5d7c50b39fb5a67d03a4562bae8c8a761fe07d50\n","  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n","  Building wheel for multiprocess (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for multiprocess: filename=multiprocess-0.70.9-cp36-none-any.whl size=100646 sha256=78bbe71a46d608d23d5774ec32f77724cf3ece3e52760b75e42de3fb367f1f8b\n","  Stored in directory: /root/.cache/pip/wheels/96/20/ac/9f1d164f7d81787cd6f4401b1d05212807d021fbbbcc301b82\n","Successfully built dill future multiprocess\n","\u001b[31mERROR: tensorflow 2.4.0 has requirement numpy~=1.19.2, but you'll have numpy 1.18.4 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow 2.4.0 has requirement six~=1.15.0, but you'll have six 1.14.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: nbclient 0.5.1 has requirement jupyter-client>=6.1.5, but you'll have jupyter-client 5.3.5 which is incompatible.\u001b[0m\n","\u001b[31mERROR: google-colab 1.0.0 has requirement six~=1.15.0, but you'll have six 1.14.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Installing collected packages: typed-ast, lazy-object-proxy, six, astroid, dill, future, isort, kiwisolver, numpy, matplotlib, mccabe, multiprocess, nose, opencv-python, toml, pylint\n","  Found existing installation: six 1.15.0\n","    Uninstalling six-1.15.0:\n","      Successfully uninstalled six-1.15.0\n","  Found existing installation: dill 0.3.3\n","    Uninstalling dill-0.3.3:\n","      Successfully uninstalled dill-0.3.3\n","  Found existing installation: future 0.16.0\n","    Uninstalling future-0.16.0:\n","      Successfully uninstalled future-0.16.0\n","  Found existing installation: kiwisolver 1.3.1\n","    Uninstalling kiwisolver-1.3.1:\n","      Successfully uninstalled kiwisolver-1.3.1\n","  Found existing installation: numpy 1.19.4\n","    Uninstalling numpy-1.19.4:\n","      Successfully uninstalled numpy-1.19.4\n","  Found existing installation: matplotlib 3.2.2\n","    Uninstalling matplotlib-3.2.2:\n","      Successfully uninstalled matplotlib-3.2.2\n","  Found existing installation: multiprocess 0.70.11.1\n","    Uninstalling multiprocess-0.70.11.1:\n","      Successfully uninstalled multiprocess-0.70.11.1\n","  Found existing installation: opencv-python 4.1.2.30\n","    Uninstalling opencv-python-4.1.2.30:\n","      Successfully uninstalled opencv-python-4.1.2.30\n","  Found existing installation: toml 0.10.2\n","    Uninstalling toml-0.10.2:\n","      Successfully uninstalled toml-0.10.2\n","Successfully installed astroid-2.4.1 dill-0.3.1.1 future-0.18.2 isort-4.3.21 kiwisolver-1.2.0 lazy-object-proxy-1.4.3 matplotlib-3.2.1 mccabe-0.6.1 multiprocess-0.70.9 nose-1.3.7 numpy-1.18.4 opencv-python-4.2.0.34 pylint-2.5.2 six-1.14.0 toml-0.10.1 typed-ast-1.4.2\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["kiwisolver","matplotlib","mpl_toolkits","numpy","six"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WwDwfnuKnykM","executionInfo":{"status":"ok","timestamp":1609599781110,"user_tz":-480,"elapsed":994,"user":{"displayName":"RNG Silvercraft","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GixYWJwJzPdOQkG39SsvVxUA8iPWxpzup0X_Rfi=s64","userId":"04284112311881935550"}},"outputId":"047ea467-6307-4ab5-c6d0-03212a20ad21"},"source":["%cd /content"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"30XHuIjImcCr","executionInfo":{"status":"ok","timestamp":1609599880607,"user_tz":-480,"elapsed":1252,"user":{"displayName":"RNG Silvercraft","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GixYWJwJzPdOQkG39SsvVxUA8iPWxpzup0X_Rfi=s64","userId":"04284112311881935550"}}},"source":["import sys\r\n","import os\r\n","import glob\r\n","import re\r\n","import math\r\n","import cvxpy as cp\r\n","import numpy as np\r\n","import cv2 as cv\r\n","import matplotlib.pyplot as plt\r\n"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"SBXgYCHNmdl6"},"source":["'''\r\n","Sets up the directory folder structure/ensures that there is a \r\n","data folder which contains the output folder a frames folder \r\n","from which to extract/read frames from and a matches folder for which \r\n","framewise pair matches are placed into for debugging\r\n","'''\r\n","def setup_folders():\r\n","  try: \r\n","    if not os.path.exists('data'): \r\n","      os.makedirs('data')\r\n","    if not os.path.exists('data/frames'):\r\n","      os.makedirs('data/frames')\r\n","    if not os.path.exists('data/output'):\r\n","      os.makedirs('data/output')\r\n","    if not os.path.exists('data/matches'):\r\n","      os.makedirs('data/matches')\r\n","  except OSError: \r\n","      print ('Error: Creating directory') "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pNdrZTDOmgkk","executionInfo":{"status":"ok","timestamp":1609599884620,"user_tz":-480,"elapsed":1074,"user":{"displayName":"RNG Silvercraft","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GixYWJwJzPdOQkG39SsvVxUA8iPWxpzup0X_Rfi=s64","userId":"04284112311881935550"}}},"source":["'''\r\n","Given the path to a video extracts the frames from the video to the \r\n","'data/frame' folder and returns a list containing all the image frames\r\n","'''\r\n","def extract_frames_from_video(filename):\r\n","  video = cv.VideoCapture(filename)\r\n","  frames = []\r\n","  currentframe = 0\r\n","  while(True): \r\n","    ret,frame = video.read() \r\n","    if ret: \r\n","      frames.append(frame)\r\n","      frame_filename = './data/frames/frame' + str(currentframe) + '.jpg'\r\n","      print ('Extracting frame...' + frame_filename) \r\n","      cv.imwrite(frame_filename, frame)\r\n","      currentframe += 1\r\n","    else: \r\n","      break\r\n","  return frames"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"j4SJf_1IminV","executionInfo":{"status":"ok","timestamp":1609599892314,"user_tz":-480,"elapsed":795,"user":{"displayName":"RNG Silvercraft","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GixYWJwJzPdOQkG39SsvVxUA8iPWxpzup0X_Rfi=s64","userId":"04284112311881935550"}}},"source":["'''\r\n","Given a directory reads the images in ascending order of filename and\r\n","returns the sequence of images in a list. Saves on having to extract frames\r\n","from the video each time\r\n","'''\r\n","def read_frames_from_dir(directory):\r\n","  if not os.path.exists(directory):\r\n","    print (\"Error directory does not exist\")\r\n","    exit()\r\n","  frames = []\r\n","  count = 0\r\n","  filenames = glob.glob(directory+ \"/*.jpg\")\r\n","  filenames.sort(key=lambda f: int(re.sub('\\D', '', f)))\r\n","  for file in filenames:\r\n","    # the following can be uncommmented to limit the number of frames read\r\n","    if count >= 300:\r\n","      break\r\n","    frames.append(cv.imread(file))\r\n","    count+=1\r\n","  print (\"read \" + str(len(frames)) + \" frames from directory\")\r\n","  return frames"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"9LXi0zE3mmy7","executionInfo":{"status":"ok","timestamp":1609599895287,"user_tz":-480,"elapsed":1019,"user":{"displayName":"RNG Silvercraft","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GixYWJwJzPdOQkG39SsvVxUA8iPWxpzup0X_Rfi=s64","userId":"04284112311881935550"}}},"source":["'''\r\n","Given a list of images which are frames of a video extracts the features \r\n","from each and returns a list of tuples containing the (keypoint, descriptor).\r\n","The feature detection algorithm used is ORB\r\n","'''\r\n","def extract_features(frames):\r\n","  print (\"extracting features...\")\r\n","  features = []\r\n","  for i in range(len(frames)):\r\n","    orb = cv.ORB_create()\r\n","    gray = cv.cvtColor(frames[i], cv.COLOR_BGR2GRAY)\r\n","    kp, des = orb.detectAndCompute(gray, None)\r\n","    while np.array(kp).shape[0] == 0:\r\n","      orb_less_accurate = cv.ORB_create(nfeatures=1000, scoreType=cv.ORB_FAST_SCORE)\r\n","      print(\"frame: \" + str(i) + \" has no keypoints\")\r\n","      kp, des = orb_less_accurate.detectAndCompute(gray, None)\r\n","    features.append((kp, des))\r\n","  return features"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"VPPANJLHmogz","executionInfo":{"status":"ok","timestamp":1609599897936,"user_tz":-480,"elapsed":917,"user":{"displayName":"RNG Silvercraft","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GixYWJwJzPdOQkG39SsvVxUA8iPWxpzup0X_Rfi=s64","userId":"04284112311881935550"}}},"source":["'''\r\n","Computes the motion between each frame and returning back a list of affine transforms\r\n","which describe the trajectory. Given n frames this method returns a list of n-1 transforms.\r\n","'''\r\n","def compute_timewise_homographies(frames, features, outputMatches=False):\r\n","  print (\"finding matches between frames...\")\r\n","  bf = cv.BFMatcher(cv.NORM_HAMMING, crossCheck = True)\r\n","  timewise_homographies = []\r\n","  for i in range(len(frames) - 1):\r\n","    matches = bf.match(features[i][1], features[i+1][1])\r\n","    if outputMatches:\r\n","      img3 = cv.drawMatches(frames[i], features[i][0], frames[i+1], features[i+1][0], matches, None, flags=2)\r\n","      cv.imwrite('data/matches/matches_' + str(i) + \"-\" + str(i+1) + \".jpg\", img3)\r\n","    src_pts = np.float32([ features[i][0][m.queryIdx].pt for m in matches ]).reshape(-1,1,2)\r\n","    dst_pts = np.float32([ features[i+1][0][m.trainIdx].pt for m in matches ]).reshape(-1,1,2)\r\n","    M, _ = cv.estimateAffine2D(src_pts, dst_pts, method=cv.RANSAC)\r\n","    if M is None:\r\n","      return timewise_homographies, i\r\n","    H = np.append(M, np.array([0, 0, 1]).reshape((1,3)), axis=0)\r\n","    timewise_homographies.append(H)\r\n","  return timewise_homographies, len(frames) - 1"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"gFYWssx9mp1z","executionInfo":{"status":"ok","timestamp":1609599900255,"user_tz":-480,"elapsed":916,"user":{"displayName":"RNG Silvercraft","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GixYWJwJzPdOQkG39SsvVxUA8iPWxpzup0X_Rfi=s64","userId":"04284112311881935550"}}},"source":["'''\r\n","Helper method to return a list of corner points with a given crop ratio from the centre \r\n","of the frame dimensions\r\n","'''\r\n","def get_corner_crop_pts(frame_dimensions, crop_ratio=0.8):\r\n","  h, w, _ = frame_dimensions\r\n","  centre_x, centre_y = (w/2, h/2)\r\n","  displacement_x, displacement_y = (crop_ratio * w)/2, (crop_ratio * h)/2\r\n","  top_left = (centre_x - displacement_x, centre_y - displacement_y)\r\n","  top_right = (centre_x + displacement_x, centre_y - displacement_y)\r\n","  bottom_left = (centre_x - displacement_x, centre_y + displacement_y)\r\n","  bottom_right = (centre_x + displacement_x, centre_y + displacement_y)\r\n","  corners = [top_left, top_right, bottom_left, bottom_right]\r\n","  return corners"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"qHCExPsdms8V","executionInfo":{"status":"ok","timestamp":1609599902406,"user_tz":-480,"elapsed":967,"user":{"displayName":"RNG Silvercraft","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GixYWJwJzPdOQkG39SsvVxUA8iPWxpzup0X_Rfi=s64","userId":"04284112311881935550"}}},"source":["'''\r\n","Given the original trajectory of the camera and a crop ratio returns a smooth trajectory\r\n","by using the linear programming technique described in the paper Auto-Directed Video \r\n","Stabilization with Robust L1 Optimal Camera Paths\r\n","(https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/37041.pdf)\r\n","'''\r\n","def compute_smooth_path(frame_dimensions, timewise_homographies=[], crop_ratio=0.8):\r\n","  print(\"computing smooth path...\")\r\n","\r\n","  n = len(timewise_homographies)\r\n","\r\n","  # \r\n","  # (dx, dy, a, b, c, d)  <- form for the smooth_path vector\r\n","  # \r\n","  # | a   b   dx  |       | a   c   0  |\r\n","  # | c   d   dy  |   ->  | b   d   0  |\r\n","  # | 0   0   1   |   T   | dx  dy  1  |\r\n","  #\r\n","\r\n","  weight_constant = 10                                          # weight towards constant 0 velocity path\r\n","  weight_linear = 1                                             # weight towards segments with a constant non-zero velocity \r\n","  weight_parabolic =  100                                       # weight towards segments with parabolic motion\r\n","  affine_weights = np.transpose([1, 1, 100, 100, 100, 100])     # weighting of each component in the path vector we want to weight the affine portion more than the translation components\r\n","  smooth_path = cp.Variable((n, 6))                             # matrix of the n smooth paths vectors that we are optimising to find \r\n","  slack_var_1 = cp.Variable((n, 6))                             # Slack variable for constraining residual 1\r\n","  slack_var_2 = cp.Variable((n, 6))                             # Slack variable for constraining residual 2\r\n","  slack_var_3 = cp.Variable((n, 6))                             # Slack variable for constraining residual 3\r\n","\r\n","\r\n","  # We define our optimisation as c^T @ e \r\n","  objective = cp.Minimize(cp.sum((weight_constant * (slack_var_1 @ affine_weights)) +\r\n","                                  (weight_linear * (slack_var_2 @ affine_weights)) +\r\n","                                  (weight_parabolic * (slack_var_3 @ affine_weights)), axis=0))\r\n","  constraints = []\r\n","\r\n","  # proximity constriants\r\n","  # U is used to extract components from the vector smooth_path. We want to constrain \r\n","  # the values of our path vector to the following: \r\n","  # 0.9 <= a, d <= 1.1\r\n","  # -0.1 <= b, c <= 0.1\r\n","  # -0.1 <= a - d <= 0.1\r\n","  # -0.051 <= b + c <= 0.05\r\n","  U = np.array([0, 0, 0, 0, 0, 0,\r\n","                0, 0, 0, 0, 0, 0,\r\n","                1, 0, 0, 0, 1, 0,\r\n","                0, 1, 0, 0, 0, 1,\r\n","                0, 0, 1, 0, 0, 1,\r\n","                0, 0, 0, 1, -1, 0]).reshape(6, 6)\r\n","  lb = np.array([0.9, -0.1, -0.1, 0.9, -0.1, -0.05])\r\n","  ub = np.array([1.1, 0.1, 0.1, 1.1, 0.1, 0.05])\r\n","  proximity = smooth_path @ U\r\n","  for i in range(n):\r\n","    constraints.append(proximity[i, :] >= lb)\r\n","    constraints.append(proximity[i, :] <= ub)\r\n","  \r\n","  # inclusion constraints for the crop corners\r\n","  # want to make sure the corner points when projected are within the frame dimensions\r\n","  corners = get_corner_crop_pts(frame_dimensions)\r\n","  for corner in corners:\r\n","    x, y = corner\r\n","    projected_x = smooth_path @ np.transpose([1, 0, x, y, 0, 0])\r\n","    projected_y = smooth_path @ np.transpose([0, 1, 0, 0, x, y])\r\n","    constraints.append(projected_x >= 0)\r\n","    constraints.append(projected_y >= 0)\r\n","    constraints.append(projected_x <= frame_dimensions[1])\r\n","    constraints.append(projected_y <= frame_dimensions[0])\r\n","  \r\n","  # Smoothness constraints\r\n","  constraints.append(slack_var_1 >= 0)\r\n","  constraints.append(slack_var_2 >= 0)\r\n","  constraints.append(slack_var_3 >= 0)\r\n","\r\n","  for i in range(n - 3):\r\n","    # Extract smooth path component variables into a matrix we can then use to calculate each residual\r\n","    # Residual 1 is for the constant zero velocity path\r\n","    # Residual 2 is for the constant non-zero velocity path\r\n","    # Residual 3 is for the parabolic non zero acceleration path\r\n","    B_t = np.array([smooth_path[i, 2], smooth_path[i, 4], 0, smooth_path[i, 3], smooth_path[i, 5], 0, smooth_path[i, 0], smooth_path[i, 1], 1]).reshape((3,3))\r\n","    B_t1 = np.array([smooth_path[i+1, 2], smooth_path[i+1, 4], 0, smooth_path[i+1, 3], smooth_path[i+1, 5], 0, smooth_path[i+1, 0], smooth_path[i+1, 1], 1]).reshape((3,3))\r\n","    B_t2 = np.array([smooth_path[i+2, 2], smooth_path[i+2, 4], 0, smooth_path[i+2, 3], smooth_path[i+2, 5], 0, smooth_path[i+2, 0], smooth_path[i+2, 1], 1]).reshape((3,3))\r\n","    B_t3 = np.array([smooth_path[i+3, 2], smooth_path[i+3, 4], 0, smooth_path[i+3, 3], smooth_path[i+3, 5], 0, smooth_path[i+3, 0], smooth_path[i+3, 1], 1]).reshape((3,3))\r\n","\r\n","    residual_t = np.transpose(timewise_homographies[i + 1]) @ B_t1  - B_t\r\n","    residual_t1 = np.transpose(timewise_homographies[i + 2]) @ B_t2 - B_t1\r\n","    residual_t2 = np.transpose(timewise_homographies[i + 3]) @ B_t3 - B_t2\r\n","    residual_t = np.array([residual_t[2, 0], residual_t[2, 1], residual_t[0, 0], residual_t[1, 0], residual_t[0, 1], residual_t[1, 1]])\r\n","    residual_t1 = np.array([residual_t1[2, 0], residual_t1[2, 1], residual_t1[0, 0], residual_t1[1, 0], residual_t1[0, 1], residual_t1[1, 1]])\r\n","    residual_t2 = np.array([residual_t2[2, 0], residual_t2[2, 1], residual_t2[0, 0], residual_t2[1, 0], residual_t2[0, 1], residual_t2[1, 1]])\r\n","\r\n","    # this is where the actual smoothness constraint is obtained from the residuals\r\n","    # i.e. this is where we summarized the following:\r\n","    #  -e_t1 <= R_t(p) < e_t1\r\n","    #  -e_t2 <= R_t1(p) - R_t(p) < e_t2\r\n","    #  -e_t3 <= R_t2(p) - 2R_t1(p) + R_t(p) < e_t3\r\n","    # if we can vectorize the below constraints we can speed this up and most likely get better results\r\n","    # being able to smooth over more frames\r\n","    for j in range(6):\r\n","      constraints.append(residual_t[j] <= slack_var_1[i, j])\r\n","      constraints.append(residual_t[j] >= -slack_var_1[i, j])\r\n","      constraints.append((residual_t1[j] - residual_t[j]) <= slack_var_2[i, j])\r\n","      constraints.append((residual_t1[j] - residual_t[j]) >= -slack_var_2[i, j])\r\n","      constraints.append((residual_t2[j] - 2*residual_t1[j] + residual_t[j]) <= slack_var_3[i, j])\r\n","      constraints.append((residual_t2[j] - 2*residual_t1[j] + residual_t[j]) >= -slack_var_3[i, j])\r\n","      \r\n","  for i in range(n-3, n):\r\n","    constraints.append(smooth_path[i, 5] == smooth_path[n-1, 5])\r\n","  \r\n","  problem = cp.Problem(objective, constraints)\r\n","  problem.solve(parallel=True, verbose=True)\r\n","  print(\"status:\", problem.status)\r\n","  print(\"optimal value\", problem.value)\r\n","  print(smooth_path.value)\r\n","  return convert_path_to_homography(smooth_path.value, n)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"rkIgjiK4mu8c","executionInfo":{"status":"ok","timestamp":1609599905943,"user_tz":-480,"elapsed":722,"user":{"displayName":"RNG Silvercraft","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GixYWJwJzPdOQkG39SsvVxUA8iPWxpzup0X_Rfi=s64","userId":"04284112311881935550"}}},"source":["'''\r\n","converts each vector in the list path to a matrix of the form below:\r\n","                              | a   b   dx  | \r\n","  |dx dy a b c d|    to ->    | c   d   dy  |\r\n","                              | 0   0   1   |\r\n","and returns the list of numpy matrices\r\n","'''\r\n","def convert_path_to_homography(path, n):\r\n","  smooth_homography = []\r\n","  for i in range(n):\r\n","    smooth_homography.append(np.array([path[i, 2], path[i, 3], path[i, 0], \r\n","                                        path[i, 4], path[i, 5], path[i, 1], \r\n","                                        0, 0, 1]).reshape(3, 3))\r\n","  return smooth_homography"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"75myMAhfmxZW","executionInfo":{"status":"ok","timestamp":1609599907825,"user_tz":-480,"elapsed":829,"user":{"displayName":"RNG Silvercraft","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GixYWJwJzPdOQkG39SsvVxUA8iPWxpzup0X_Rfi=s64","userId":"04284112311881935550"}}},"source":["'''\r\n","Applies the smooth path the original frames cropping them to the \r\n","given crop ratio. Writes the new frames to the subdirectory \r\n","'data/output/'\r\n","'''\r\n","def apply_smoothing(original_frames, smooth_path, crop_ratio=0.8):\r\n","  print(\"smoothing new frames...\")\r\n","\r\n","  n = len(original_frames)\r\n","  h, w, _ = original_frames[0].shape\r\n","  centre_x, centre_y = (w/2, h/2)\r\n","  displacement_x, displacement_y = (crop_ratio * w)/2, (crop_ratio * h)/2\r\n","\r\n","  # get the displaced corner points from the centre of the frame which will become the \r\n","  # corners of the resulting frame\r\n","  top_left = np.array([centre_x - displacement_x, centre_y - displacement_y, 1])\r\n","  top_right = np.array([centre_x + displacement_x, centre_y - displacement_y, 1])\r\n","  bottom_left = np.array([centre_x - displacement_x, centre_y + displacement_y, 1])\r\n","  bottom_right = np.array([centre_x + displacement_x, centre_y + displacement_y, 1])\r\n","  crop_corners = [top_left, top_right, bottom_left, bottom_right]\r\n","  dst_corners = np.array([[0, 0], [w, 0], [0, h], [w, h]]).astype(np.float32)\r\n","\r\n","  # cycle through each frame projecting the corner to the smooth position and then \r\n","  # find the resulting homography which can move the corners to the edges of the frame\r\n","  # then warp the original frame according to this homography\r\n","  new_frames = []\r\n","  for i in range(n-1):\r\n","    projected_corners = []\r\n","    for corner in crop_corners:\r\n","      projected_corners.append(smooth_path[i-1].dot(corner))\r\n","    src_corners = np.array([[projected_corners[0][0], projected_corners[0][1]],\r\n","                            [projected_corners[1][0], projected_corners[1][1]], \r\n","                            [projected_corners[2][0], projected_corners[2][1]],\r\n","                            [projected_corners[3][0], projected_corners[3][1]]]).astype(np.float32)\r\n","    # H, _ = cv.findHomography(src_corners, dst_corners, cv.RANSAC, 5.0)\r\n","    warp_frame = cv.warpPerspective(original_frames[i], smooth_path[i], (original_frames[i].shape[1], original_frames[i].shape[0]))\r\n","    frame_filename = './data/output/frame' + str(i) + '.jpg'\r\n","    cv.imwrite(frame_filename, warp_frame)\r\n","    new_frames.append(warp_frame)\r\n","  return new_frames"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"MPiNeHHanG0c","executionInfo":{"status":"ok","timestamp":1609599910401,"user_tz":-480,"elapsed":607,"user":{"displayName":"RNG Silvercraft","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GixYWJwJzPdOQkG39SsvVxUA8iPWxpzup0X_Rfi=s64","userId":"04284112311881935550"}}},"source":["'''\r\n","Graphs the trajectory of the original and smooth paths and \r\n","saves the graph as motion.png\r\n","'''\r\n","def graph_paths(timewise_homographies=[], smooth_path=[]):\r\n","  print(\"graphing path...\")\r\n","  n = len(timewise_homographies)\r\n","  original_x_path = np.zeros(n-1)\r\n","  original_y_path = np.zeros(n-1)\r\n","  original_dx = np.zeros(n-1)\r\n","  original_dy = np.zeros(n-1)\r\n","  smooth_x_path = np.zeros(n-1)\r\n","  smooth_y_path = np.zeros(n-1)\r\n","  smooth_dx_path = np.zeros(n-1)\r\n","  smooth_dy_path = np.zeros(n-1)\r\n","  pt = np.array([1, 1, 1])\r\n","\r\n","  # push point through the path and collect the result\r\n","  for i in range(n-1):\r\n","    pt = timewise_homographies[i].dot(pt)\r\n","    original_x_path[i] = pt[0]\r\n","    original_y_path[i] = pt[1]\r\n","    # original_dx[i] = timewise_homographies[i][0,2]\r\n","    # original_dy[i] = timewise_homographies[i][1,2]\r\n","    smooth_pt = smooth_path[i].dot(pt)\r\n","    smooth_x_path[i] = smooth_pt[0]\r\n","    smooth_y_path[i] = smooth_pt[1]\r\n","    # smooth_dx_path[i] = smooth_path[i][0,2]\r\n","    # smooth_dy_path[i] = smooth_path[i][1,2]\r\n","\r\n","  # place data on the subplots\r\n","  fig, axs = plt.subplots(1,2)\r\n","  axs[0].set_title('x path')\r\n","  axs[0].plot(np.arange(0, n-1), original_x_path, '-r')\r\n","  axs[0].plot(np.arange(0, n-1), smooth_x_path, '-g')\r\n","  axs[1].set_title('y path')\r\n","  axs[1].plot(np.arange(0, n-1), original_y_path, '-r')\r\n","  axs[1].plot(np.arange(0, n-1), smooth_y_path, '-g')\r\n","  # axs[1, 0].set_title('dx path')\r\n","  # axs[1, 0].plot(np.arange(0, n-1), original_dx, '-r')\r\n","  # axs[1, 0].plot(np.arange(0, n-1), smooth_dx_path, '-g')\r\n","  # axs[1, 1].set_title('dy path')\r\n","  # axs[1, 1].plot(np.arange(0, n-1), original_dy, '-r')\r\n","  # axs[1, 1].plot(np.arange(0, n-1), smooth_dy_path, '-g')\r\n","  plt.savefig('motion.png')\r\n","  plt.show()"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"V9bMIsyUhbPx"},"source":["#main\r\n","#setup_folders()\r\n","original_frames = read_frames_from_dir(\"01_Regular.mp4\")\r\n","features = extract_features(original_frames)\r\n","timewise_homographies, _ = compute_timewise_homographies(original_frames, features)\r\n","smooth_path = compute_smooth_path(original_frames[0].shape, timewise_homographies)\r\n","apply_smoothing(original_frames, smooth_path)\r\n","graph_paths(timewise_homographies, smooth_path)\r\n","  "],"execution_count":null,"outputs":[]}]}